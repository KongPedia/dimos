#!/usr/bin/env python3

# Copyright 2025 Dimensional Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
import threading
from typing import List, Optional

import cv2
import numpy as np

from dimos.core import Module, In, Out, rpc
from dimos.msgs.geometry_msgs import PoseStamped
from dimos.msgs.sensor_msgs import Image, ImageFormat
from dimos_lcm.sensor_msgs import CameraInfo
from dimos.msgs.std_msgs import Header
from dimos.protocol.tf import TF
from dimos.utils.logging_config import setup_logger

logger = setup_logger(__name__)


class UnitreeCameraModule(Module):
    """
    Camera module for Unitree Go2 that processes RGB images to generate depth using Metric3D.

    Subscribes to:
        - /go2/color_image: RGB camera images from Unitree

    Publishes:
        - /go2/depth_image: Depth images generated by Metric3D
        - /go2/camera_info: Camera calibration information
        - /go2/camera_pose: Camera pose from TF lookup
    """

    # LCM inputs
    color_image: In[Image] = None

    # LCM outputs
    depth_image: Out[Image] = None
    camera_info: Out[CameraInfo] = None
    camera_pose: Out[PoseStamped] = None

    def __init__(
        self,
        camera_intrinsics: List[float],
        world_frame_id: str = "world",
        camera_frame_id: str = "camera_link",
        base_frame_id: str = "base_link",
        gt_depth_scale: float = 2.0,
        **kwargs,
    ):
        """
        Initialize Unitree Camera Module.

        Args:
            camera_intrinsics: Camera intrinsics [fx, fy, cx, cy]
            camera_frame_id: TF frame ID for camera
            base_frame_id: TF frame ID for robot base
        """
        super().__init__(**kwargs)

        if len(camera_intrinsics) != 4:
            raise ValueError("Camera intrinsics must be [fx, fy, cx, cy]")

        self.camera_intrinsics = camera_intrinsics
        self.camera_frame_id = camera_frame_id
        self.base_frame_id = base_frame_id
        self.world_frame_id = world_frame_id

        # Initialize components
        from dimos.models.depth.metric3d import Metric3D

        self.metric3d = Metric3D(camera_intrinsics=self.camera_intrinsics)
        self.gt_depth_scale = gt_depth_scale
        self.tf = TF()

        # Processing state
        self._running = False
        self._latest_frame = None
        self._last_image = None
        self._last_timestamp = None
        self._last_depth = None
        self._cannot_process_depth = False

        # Threading
        self._processing_thread: Optional[threading.Thread] = None
        self._stop_processing = threading.Event()

        logger.info(f"UnitreeCameraModule initialized with intrinsics: {camera_intrinsics}")

    @rpc
    def start(self):
        """Start the camera module."""
        if self._running:
            logger.warning("Camera module already running")
            return

        # Set running flag before starting
        self._running = True

        # Subscribe to video input
        self.color_image.subscribe(self._on_video)

        # Start processing thread
        self._start_processing_thread()

        logger.info("Camera module started")

    @rpc
    def stop(self):
        """Stop the camera module."""
        if not self._running:
            return

        self._running = False
        self._stop_processing.set()

        # Wait for thread to finish
        if self._processing_thread and self._processing_thread.is_alive():
            self._processing_thread.join(timeout=2.0)

        logger.info("Camera module stopped")

    def _on_video(self, msg: Image):
        """Store latest video frame for processing."""
        if not self._running:
            return

        # Simply store the latest frame - processing happens in main loop
        self._latest_frame = msg
        logger.debug(
            f"Received video frame: format={msg.format}, shape={msg.data.shape if hasattr(msg.data, 'shape') else 'unknown'}"
        )

    def _start_processing_thread(self):
        """Start the processing thread."""
        self._stop_processing.clear()
        self._processing_thread = threading.Thread(target=self._main_processing_loop, daemon=True)
        self._processing_thread.start()
        logger.info("Started camera processing thread")

    def _main_processing_loop(self):
        """Main processing loop that continuously processes latest frames."""
        logger.info("Starting main processing loop")

        while not self._stop_processing.is_set():
            # Process latest frame if available
            if self._latest_frame is not None:
                try:
                    msg = self._latest_frame
                    self._latest_frame = None  # Clear to avoid reprocessing
                    # Store for publishing
                    self._last_image = msg.data
                    self._last_timestamp = msg.ts if msg.ts else time.time()
                    # Process depth
                    self._process_depth(self._last_image)

                except Exception as e:
                    logger.error(f"Error in main processing loop: {e}", exc_info=True)
            else:
                # Small sleep to avoid busy waiting
                time.sleep(0.001)

        logger.info("Main processing loop stopped")

    def _process_depth(self, img_array: np.ndarray):
        """Process depth estimation using Metric3D."""
        if self._cannot_process_depth:
            self._last_depth = None
            return

        try:
            logger.debug(f"Processing depth for image shape: {img_array.shape}")

            # Generate depth map
            depth_array = self.metric3d.infer_depth(img_array) / self.gt_depth_scale

            self._last_depth = depth_array
            logger.debug(f"Generated depth map shape: {depth_array.shape}")

            self._publish_synchronized_data()

        except Exception as e:
            logger.error(f"Error processing depth: {e}", exc_info=True)
            self._cannot_process_depth = True

    def _publish_synchronized_data(self):
        """Publish all data synchronously."""
        if not self._running:
            return

        try:
            # Create header
            header = Header(self.camera_frame_id)

            logger.debug("Publishing synchronized camera data")

            # Publish depth image
            if self._last_depth is not None:
                # Convert depth to uint16 (millimeters) for more efficient storage
                # Clamp to valid range [0, 65.535] meters before converting
                depth_clamped = np.clip(self._last_depth, 0, 65.535)
                depth_uint16 = (depth_clamped * 1000).astype(np.uint16)
                depth_msg = Image(
                    data=depth_uint16,
                    format=ImageFormat.DEPTH16,  # Use DEPTH16 format for uint16 depth
                    frame_id=header.frame_id,
                    ts=header.ts,
                )
                self.depth_image.publish(depth_msg)
                logger.debug(f"Published depth image (uint16): shape={depth_uint16.shape}")

            # Publish camera info
            self._publish_camera_info(header)

            # Publish camera pose
            self._publish_camera_pose(header)

        except Exception as e:
            logger.error(f"Error publishing synchronized data: {e}", exc_info=True)

    def _publish_camera_info(self, header: Header):
        """Publish camera calibration information."""
        try:
            # Extract intrinsics
            fx, fy, cx, cy = self.camera_intrinsics

            # Get image dimensions from last image
            height, width = self._last_image.shape[:2]

            # Camera matrix K (3x3)
            K = [fx, 0, cx, 0, fy, cy, 0, 0, 1]

            # No distortion coefficients for now
            D = [0.0, 0.0, 0.0, 0.0, 0.0]

            # Identity rotation matrix
            R = [1, 0, 0, 0, 1, 0, 0, 0, 1]

            # Projection matrix P (3x4)
            P = [fx, 0, cx, 0, 0, fy, cy, 0, 0, 0, 1, 0]

            msg = CameraInfo(
                D_length=len(D),
                header=header,
                height=height,
                width=width,
                distortion_model="plumb_bob",
                D=D,
                K=K,
                R=R,
                P=P,
                binning_x=0,
                binning_y=0,
            )

            self.camera_info.publish(msg)

        except Exception as e:
            logger.error(f"Error publishing camera info: {e}")

    def _publish_camera_pose(self, header: Header):
        """Publish camera pose from TF lookup."""
        try:
            # Look up transform from base_link to camera_link
            transform = self.tf.get(
                parent_frame=self.world_frame_id,
                child_frame=self.camera_frame_id,
                time_point=header.ts,
                time_tolerance=1.0,
            )

            if transform:
                # Create PoseStamped from transform
                pose_msg = PoseStamped(
                    ts=header.ts,
                    frame_id=self.camera_frame_id,
                    position=transform.translation,
                    orientation=transform.rotation,
                )
                self.camera_pose.publish(pose_msg)
            else:
                logger.warning(
                    f"Could not find transform from {self.base_frame_id} to {self.camera_frame_id}"
                )

        except Exception as e:
            logger.error(f"Error publishing camera pose: {e}")

    @rpc
    def get_camera_intrinsics(self) -> List[float]:
        """Get camera intrinsics."""
        return self.camera_intrinsics

    def cleanup(self):
        """Clean up resources on module destruction."""
        self.stop()
        self.metric3d.cleanup()
